{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Reading a long time series from Lorenz 96 X-values and training a \n",
    "neural network to behave as the Lorenz 96 system.\n",
    "\n",
    "Copyright (C) 2020  SINTEF Digital\n",
    "\n",
    "This program is free software: you can redistribute it and/or modify\n",
    "it under the terms of the GNU General Public License as published by\n",
    "the Free Software Foundation, either version 3 of the License, or\n",
    "(at your option) any later version.\n",
    "\n",
    "This program is distributed in the hope that it will be useful,\n",
    "but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "GNU General Public License for more details.\n",
    "\n",
    "You should have received a copy of the GNU General Public License\n",
    "along with this program.  If not, see <http://www.gnu.org/licenses/>.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuration and evaluation of the neural network is taken from:\n",
    "the [supplementary material](https://www.geosci-model-dev.net/11/3999/2018/gmd-11-3999-2018-discussion.html) for the article *Challenges and design choices for global weather and climate models based on machine learning* by P. Dueben and P. Bauer, published in [Geosci. Model Dev., 11, 3999â€“4009, 2018](https://doi.org/10.5194/gmd-11-3999-2018)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets have matplotlib \"inline\"\n",
    "%matplotlib inline\n",
    "#%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "#Import packages we need\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import math\n",
    "\n",
    "import tensorflow.keras \n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.optimizers import RMSprop, SGD, Adagrad, Adadelta\n",
    "import json\n",
    "\n",
    "#Helpful during development\n",
    "import importlib\n",
    "#importlib.reload(module)\n",
    "\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import animation, rc\n",
    "\n",
    "\n",
    "#Set large figure sizes\n",
    "#plt.rcParams[\"animation.html\"] = \"jshtml\" #Javascript \n",
    "plt.rcParams[\"animation.html\"] = \"html5\" #mp4\n",
    "plt.rcParams[\"figure.dpi\"] = 100.0 #highres movies/plots\n",
    "\n",
    "plt.rcParams[\"text.usetex\"] = True\n",
    "plt.rcParams[\"font.family\"] = 'serif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read data\n",
    "normalized_run = np.load('data/training_data_2020_05_04-15_13_21/normalized_run.npz')\n",
    "X = normalized_run['X']\n",
    "n_run = X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organize in input and output \n",
    "# We train the network based on the connection between input and increment.\n",
    "X_input = X[:-1,:]\n",
    "X_output = X[1:,:]\n",
    "X_delta = X_output - X_input \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Neural-network structure using the global structure\n",
    "model = Sequential()\n",
    "model.add(Dense(8, input_dim=8, activation='tanh'))\n",
    "model.add(Dense(100, activation='tanh'))\n",
    "model.add(Dense(100, activation='tanh'))\n",
    "model.add(Dense(100, activation='tanh'))\n",
    "model.add(Dense(100, activation='tanh'))\n",
    "model.add(Dense(8, activation='tanh'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model with stochastic gradient descent\n",
    "model.compile(loss='mean_absolute_error', optimizer='SGD', metrics=['mae'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1600000 samples, validate on 400000 samples\n",
      "Epoch 1/200\n",
      "1600000/1600000 [==============================] - 26s 16us/sample - loss: 0.0287 - mae: 0.0287 - val_loss: 0.0235 - val_mae: 0.0235\n",
      "Epoch 2/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0196 - mae: 0.0196 - val_loss: 0.0159 - val_mae: 0.0159\n",
      "Epoch 3/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0143 - mae: 0.0143 - val_loss: 0.0126 - val_mae: 0.0126\n",
      "Epoch 4/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0119 - mae: 0.0119 - val_loss: 0.0113 - val_mae: 0.0113\n",
      "Epoch 5/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0104 - mae: 0.0104 - val_loss: 0.0095 - val_mae: 0.0095\n",
      "Epoch 6/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0094 - mae: 0.0094 - val_loss: 0.0092 - val_mae: 0.0092\n",
      "Epoch 7/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0083 - val_mae: 0.0083\n",
      "Epoch 8/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0082 - mae: 0.0082 - val_loss: 0.0080 - val_mae: 0.0080\n",
      "Epoch 9/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0077 - mae: 0.0077 - val_loss: 0.0074 - val_mae: 0.0074\n",
      "Epoch 10/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0073 - mae: 0.0073 - val_loss: 0.0070 - val_mae: 0.0070\n",
      "Epoch 11/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0070 - mae: 0.0070 - val_loss: 0.0068 - val_mae: 0.0068\n",
      "Epoch 12/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0068 - mae: 0.0068 - val_loss: 0.0068 - val_mae: 0.0068\n",
      "Epoch 13/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0066 - mae: 0.0066 - val_loss: 0.0069 - val_mae: 0.0069\n",
      "Epoch 14/200\n",
      "1600000/1600000 [==============================] - 26s 16us/sample - loss: 0.0063 - mae: 0.0063 - val_loss: 0.0064 - val_mae: 0.0064\n",
      "Epoch 15/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0062 - mae: 0.0062 - val_loss: 0.0060 - val_mae: 0.0060\n",
      "Epoch 16/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0060 - mae: 0.0060 - val_loss: 0.0060 - val_mae: 0.0060\n",
      "Epoch 17/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0059 - mae: 0.0059 - val_loss: 0.0058 - val_mae: 0.0058\n",
      "Epoch 18/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0057 - mae: 0.0057 - val_loss: 0.0059 - val_mae: 0.0059\n",
      "Epoch 19/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0056 - mae: 0.0056 - val_loss: 0.0057 - val_mae: 0.0057\n",
      "Epoch 20/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0055 - mae: 0.0055 - val_loss: 0.0061 - val_mae: 0.0061\n",
      "Epoch 21/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0054 - mae: 0.0054 - val_loss: 0.0052 - val_mae: 0.0052\n",
      "Epoch 22/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0053 - mae: 0.0053 - val_loss: 0.0052 - val_mae: 0.0052\n",
      "Epoch 23/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0052 - mae: 0.0052 - val_loss: 0.0051 - val_mae: 0.0051\n",
      "Epoch 24/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0052 - mae: 0.0052 - val_loss: 0.0051 - val_mae: 0.0051\n",
      "Epoch 25/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0051 - mae: 0.0051 - val_loss: 0.0052 - val_mae: 0.0052\n",
      "Epoch 26/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0050 - mae: 0.0050 - val_loss: 0.0053 - val_mae: 0.0053\n",
      "Epoch 27/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0050 - mae: 0.0050 - val_loss: 0.0052 - val_mae: 0.0052\n",
      "Epoch 28/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0049 - mae: 0.0049 - val_loss: 0.0049 - val_mae: 0.0049\n",
      "Epoch 29/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0049 - mae: 0.0049 - val_loss: 0.0048 - val_mae: 0.0048\n",
      "Epoch 30/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0048 - mae: 0.0048 - val_loss: 0.0046 - val_mae: 0.0046\n",
      "Epoch 31/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0048 - mae: 0.0048 - val_loss: 0.0047 - val_mae: 0.0047\n",
      "Epoch 32/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0047 - mae: 0.0047 - val_loss: 0.0049 - val_mae: 0.0049\n",
      "Epoch 33/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0047 - mae: 0.0047 - val_loss: 0.0043 - val_mae: 0.0043\n",
      "Epoch 34/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0046 - mae: 0.0046 - val_loss: 0.0043 - val_mae: 0.0043\n",
      "Epoch 35/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0046 - mae: 0.0046 - val_loss: 0.0047 - val_mae: 0.0047\n",
      "Epoch 36/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0046 - mae: 0.0046 - val_loss: 0.0048 - val_mae: 0.0048\n",
      "Epoch 37/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0045 - mae: 0.0045 - val_loss: 0.0044 - val_mae: 0.0044\n",
      "Epoch 38/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0045 - mae: 0.0045 - val_loss: 0.0044 - val_mae: 0.0044\n",
      "Epoch 39/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0045 - mae: 0.0045 - val_loss: 0.0043 - val_mae: 0.0043\n",
      "Epoch 40/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0044 - mae: 0.0044 - val_loss: 0.0044 - val_mae: 0.0044\n",
      "Epoch 41/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0044 - mae: 0.0044 - val_loss: 0.0046 - val_mae: 0.0046\n",
      "Epoch 42/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0044 - mae: 0.0044 - val_loss: 0.0042 - val_mae: 0.0042\n",
      "Epoch 43/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0044 - mae: 0.0044 - val_loss: 0.0045 - val_mae: 0.0045\n",
      "Epoch 44/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0043 - mae: 0.0043 - val_loss: 0.0043 - val_mae: 0.0043\n",
      "Epoch 45/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0043 - mae: 0.0043 - val_loss: 0.0044 - val_mae: 0.0044\n",
      "Epoch 46/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0043 - mae: 0.0043 - val_loss: 0.0043 - val_mae: 0.0043\n",
      "Epoch 47/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0042 - mae: 0.0042 - val_loss: 0.0044 - val_mae: 0.0044\n",
      "Epoch 48/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0042 - mae: 0.0042 - val_loss: 0.0042 - val_mae: 0.0042\n",
      "Epoch 49/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0042 - mae: 0.0042 - val_loss: 0.0041 - val_mae: 0.0041\n",
      "Epoch 50/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0042 - mae: 0.0042 - val_loss: 0.0038 - val_mae: 0.0038\n",
      "Epoch 51/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0042 - mae: 0.0042 - val_loss: 0.0041 - val_mae: 0.0041\n",
      "Epoch 52/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0041 - mae: 0.0041 - val_loss: 0.0043 - val_mae: 0.0043\n",
      "Epoch 53/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0041 - mae: 0.0041 - val_loss: 0.0041 - val_mae: 0.0041\n",
      "Epoch 54/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0041 - mae: 0.0041 - val_loss: 0.0039 - val_mae: 0.0039\n",
      "Epoch 55/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0041 - mae: 0.0041 - val_loss: 0.0039 - val_mae: 0.0039\n",
      "Epoch 56/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0040 - mae: 0.0040 - val_loss: 0.0041 - val_mae: 0.0041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0041 - mae: 0.0041 - val_loss: 0.0041 - val_mae: 0.0041\n",
      "Epoch 58/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0040 - mae: 0.0040 - val_loss: 0.0041 - val_mae: 0.0041\n",
      "Epoch 59/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0040 - mae: 0.0040 - val_loss: 0.0037 - val_mae: 0.0037\n",
      "Epoch 60/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0040 - mae: 0.0040 - val_loss: 0.0038 - val_mae: 0.0038\n",
      "Epoch 61/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0040 - mae: 0.0040 - val_loss: 0.0041 - val_mae: 0.0041\n",
      "Epoch 62/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0040 - mae: 0.0040 - val_loss: 0.0041 - val_mae: 0.0041\n",
      "Epoch 63/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0040 - mae: 0.0040 - val_loss: 0.0041 - val_mae: 0.0041\n",
      "Epoch 64/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0039 - mae: 0.0039 - val_loss: 0.0041 - val_mae: 0.0041\n",
      "Epoch 65/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0039 - mae: 0.0039 - val_loss: 0.0040 - val_mae: 0.0040\n",
      "Epoch 66/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0039 - mae: 0.0039 - val_loss: 0.0036 - val_mae: 0.0036\n",
      "Epoch 67/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0039 - mae: 0.0039 - val_loss: 0.0040 - val_mae: 0.0040\n",
      "Epoch 68/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0039 - mae: 0.0039 - val_loss: 0.0037 - val_mae: 0.0037\n",
      "Epoch 69/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0039 - mae: 0.0039 - val_loss: 0.0039 - val_mae: 0.0039\n",
      "Epoch 70/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0038 - mae: 0.0038 - val_loss: 0.0038 - val_mae: 0.0038\n",
      "Epoch 71/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0038 - mae: 0.0038 - val_loss: 0.0038 - val_mae: 0.0038\n",
      "Epoch 72/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0038 - mae: 0.0038 - val_loss: 0.0036 - val_mae: 0.0036\n",
      "Epoch 73/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0038 - mae: 0.0038 - val_loss: 0.0037 - val_mae: 0.0037\n",
      "Epoch 74/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0038 - mae: 0.0038 - val_loss: 0.0038 - val_mae: 0.0038\n",
      "Epoch 75/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0038 - mae: 0.0038 - val_loss: 0.0037 - val_mae: 0.0037\n",
      "Epoch 76/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0038 - mae: 0.0038 - val_loss: 0.0036 - val_mae: 0.0036\n",
      "Epoch 77/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0038 - mae: 0.0038 - val_loss: 0.0039 - val_mae: 0.0039\n",
      "Epoch 78/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0038 - mae: 0.0038 - val_loss: 0.0036 - val_mae: 0.0036\n",
      "Epoch 79/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0037 - mae: 0.0037 - val_loss: 0.0039 - val_mae: 0.0039\n",
      "Epoch 80/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0037 - mae: 0.0037 - val_loss: 0.0035 - val_mae: 0.0035\n",
      "Epoch 81/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0037 - mae: 0.0037 - val_loss: 0.0041 - val_mae: 0.0041\n",
      "Epoch 82/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0037 - mae: 0.0037 - val_loss: 0.0039 - val_mae: 0.0039\n",
      "Epoch 83/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0037 - mae: 0.0037 - val_loss: 0.0038 - val_mae: 0.0038\n",
      "Epoch 84/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0037 - mae: 0.0037 - val_loss: 0.0036 - val_mae: 0.0036\n",
      "Epoch 85/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0037 - mae: 0.0037 - val_loss: 0.0037 - val_mae: 0.0037\n",
      "Epoch 86/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0037 - mae: 0.0037 - val_loss: 0.0034 - val_mae: 0.0034\n",
      "Epoch 87/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0037 - mae: 0.0037 - val_loss: 0.0040 - val_mae: 0.0040\n",
      "Epoch 88/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0037 - mae: 0.0037 - val_loss: 0.0035 - val_mae: 0.0035\n",
      "Epoch 89/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0036 - mae: 0.0036 - val_loss: 0.0035 - val_mae: 0.0035\n",
      "Epoch 90/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0036 - mae: 0.0036 - val_loss: 0.0036 - val_mae: 0.0036\n",
      "Epoch 91/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0036 - mae: 0.0036 - val_loss: 0.0034 - val_mae: 0.0034\n",
      "Epoch 92/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0036 - mae: 0.0036 - val_loss: 0.0038 - val_mae: 0.0038\n",
      "Epoch 93/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0036 - mae: 0.0036 - val_loss: 0.0036 - val_mae: 0.0036\n",
      "Epoch 94/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0036 - mae: 0.0036 - val_loss: 0.0035 - val_mae: 0.0035\n",
      "Epoch 95/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0036 - mae: 0.0036 - val_loss: 0.0039 - val_mae: 0.0039\n",
      "Epoch 96/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0036 - mae: 0.0036 - val_loss: 0.0036 - val_mae: 0.0036\n",
      "Epoch 97/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0036 - mae: 0.0036 - val_loss: 0.0039 - val_mae: 0.0039\n",
      "Epoch 98/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0036 - mae: 0.0036 - val_loss: 0.0037 - val_mae: 0.0037\n",
      "Epoch 99/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0036 - mae: 0.0036 - val_loss: 0.0035 - val_mae: 0.0035\n",
      "Epoch 100/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0035 - mae: 0.0035 - val_loss: 0.0034 - val_mae: 0.0034\n",
      "Epoch 101/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0035 - mae: 0.0035 - val_loss: 0.0036 - val_mae: 0.0036\n",
      "Epoch 102/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0035 - mae: 0.0035 - val_loss: 0.0033 - val_mae: 0.0033\n",
      "Epoch 103/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0035 - mae: 0.0035 - val_loss: 0.0038 - val_mae: 0.0038\n",
      "Epoch 104/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0035 - mae: 0.0035 - val_loss: 0.0033 - val_mae: 0.0033\n",
      "Epoch 105/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0035 - mae: 0.0035 - val_loss: 0.0036 - val_mae: 0.0036\n",
      "Epoch 106/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0035 - mae: 0.0035 - val_loss: 0.0036 - val_mae: 0.0036\n",
      "Epoch 107/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0035 - mae: 0.0035 - val_loss: 0.0037 - val_mae: 0.0037\n",
      "Epoch 108/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0035 - mae: 0.0035 - val_loss: 0.0038 - val_mae: 0.0038\n",
      "Epoch 109/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0035 - mae: 0.0035 - val_loss: 0.0034 - val_mae: 0.0034\n",
      "Epoch 110/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0035 - mae: 0.0035 - val_loss: 0.0034 - val_mae: 0.0034\n",
      "Epoch 111/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0035 - mae: 0.0035 - val_loss: 0.0034 - val_mae: 0.0034\n",
      "Epoch 112/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0035 - mae: 0.0035 - val_loss: 0.0034 - val_mae: 0.0034\n",
      "Epoch 113/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0035 - mae: 0.0035 - val_loss: 0.0034 - val_mae: 0.0034\n",
      "Epoch 114/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0034 - mae: 0.0034 - val_loss: 0.0034 - val_mae: 0.0034\n",
      "Epoch 115/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0034 - mae: 0.0034 - val_loss: 0.0034 - val_mae: 0.0034\n",
      "Epoch 116/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0034 - mae: 0.0034 - val_loss: 0.0036 - val_mae: 0.0036\n",
      "Epoch 117/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0034 - mae: 0.0034 - val_loss: 0.0034 - val_mae: 0.0034\n",
      "Epoch 118/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0034 - mae: 0.0034 - val_loss: 0.0034 - val_mae: 0.0034\n",
      "Epoch 119/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0034 - mae: 0.0034 - val_loss: 0.0035 - val_mae: 0.0035\n",
      "Epoch 120/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0034 - mae: 0.0034 - val_loss: 0.0034 - val_mae: 0.0034\n",
      "Epoch 121/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0034 - mae: 0.0034 - val_loss: 0.0032 - val_mae: 0.0032\n",
      "Epoch 122/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0034 - mae: 0.0034 - val_loss: 0.0035 - val_mae: 0.0035\n",
      "Epoch 123/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0034 - mae: 0.0034 - val_loss: 0.0034 - val_mae: 0.0034\n",
      "Epoch 124/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0034 - mae: 0.0034 - val_loss: 0.0034 - val_mae: 0.0034\n",
      "Epoch 125/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0034 - mae: 0.0034 - val_loss: 0.0034 - val_mae: 0.0034\n",
      "Epoch 126/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0034 - mae: 0.0034 - val_loss: 0.0035 - val_mae: 0.0035\n",
      "Epoch 127/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0034 - mae: 0.0034 - val_loss: 0.0034 - val_mae: 0.0034\n",
      "Epoch 128/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0033 - mae: 0.0033 - val_loss: 0.0034 - val_mae: 0.0034\n",
      "Epoch 129/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0033 - mae: 0.0033 - val_loss: 0.0034 - val_mae: 0.0034\n",
      "Epoch 130/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0033 - mae: 0.0033 - val_loss: 0.0032 - val_mae: 0.0032\n",
      "Epoch 131/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0033 - mae: 0.0033 - val_loss: 0.0035 - val_mae: 0.0035\n",
      "Epoch 132/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0033 - mae: 0.0033 - val_loss: 0.0032 - val_mae: 0.0032\n",
      "Epoch 133/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0033 - mae: 0.0033 - val_loss: 0.0034 - val_mae: 0.0034\n",
      "Epoch 134/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0033 - mae: 0.0033 - val_loss: 0.0033 - val_mae: 0.0033\n",
      "Epoch 135/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0033 - mae: 0.0033 - val_loss: 0.0033 - val_mae: 0.0033\n",
      "Epoch 136/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0033 - mae: 0.0033 - val_loss: 0.0035 - val_mae: 0.0035\n",
      "Epoch 137/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0033 - mae: 0.0033 - val_loss: 0.0032 - val_mae: 0.0032\n",
      "Epoch 138/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0033 - mae: 0.0033 - val_loss: 0.0032 - val_mae: 0.0032\n",
      "Epoch 139/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0033 - mae: 0.0033 - val_loss: 0.0034 - val_mae: 0.0034\n",
      "Epoch 140/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0033 - mae: 0.0033 - val_loss: 0.0034 - val_mae: 0.0034\n",
      "Epoch 141/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0033 - mae: 0.0033 - val_loss: 0.0033 - val_mae: 0.0033\n",
      "Epoch 142/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0032 - mae: 0.0032 - val_loss: 0.0033 - val_mae: 0.0033\n",
      "Epoch 143/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0032 - mae: 0.0032 - val_loss: 0.0031 - val_mae: 0.0031\n",
      "Epoch 144/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0032 - mae: 0.0032 - val_loss: 0.0033 - val_mae: 0.0033\n",
      "Epoch 145/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0032 - mae: 0.0032 - val_loss: 0.0032 - val_mae: 0.0032\n",
      "Epoch 146/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0032 - mae: 0.0032 - val_loss: 0.0034 - val_mae: 0.0034\n",
      "Epoch 147/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0032 - mae: 0.0032 - val_loss: 0.0031 - val_mae: 0.0031\n",
      "Epoch 148/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0032 - mae: 0.0032 - val_loss: 0.0033 - val_mae: 0.0033\n",
      "Epoch 149/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0032 - mae: 0.0032 - val_loss: 0.0033 - val_mae: 0.0033\n",
      "Epoch 150/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0032 - mae: 0.0032 - val_loss: 0.0032 - val_mae: 0.0032\n",
      "Epoch 151/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0032 - mae: 0.0032 - val_loss: 0.0031 - val_mae: 0.0031\n",
      "Epoch 152/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0032 - mae: 0.0032 - val_loss: 0.0030 - val_mae: 0.0030\n",
      "Epoch 153/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0032 - mae: 0.0032 - val_loss: 0.0033 - val_mae: 0.0033\n",
      "Epoch 154/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0032 - mae: 0.0032 - val_loss: 0.0032 - val_mae: 0.0032\n",
      "Epoch 155/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0032 - mae: 0.0032 - val_loss: 0.0030 - val_mae: 0.0030\n",
      "Epoch 156/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0032 - mae: 0.0032 - val_loss: 0.0033 - val_mae: 0.0033\n",
      "Epoch 157/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0032 - mae: 0.0032 - val_loss: 0.0031 - val_mae: 0.0031\n",
      "Epoch 158/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0031 - mae: 0.0031 - val_loss: 0.0033 - val_mae: 0.0033\n",
      "Epoch 159/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0032 - mae: 0.0032 - val_loss: 0.0032 - val_mae: 0.0032\n",
      "Epoch 160/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0031 - mae: 0.0031 - val_loss: 0.0032 - val_mae: 0.0032\n",
      "Epoch 161/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0031 - mae: 0.0031 - val_loss: 0.0032 - val_mae: 0.0032\n",
      "Epoch 162/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0031 - mae: 0.0031 - val_loss: 0.0030 - val_mae: 0.0030\n",
      "Epoch 163/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0031 - mae: 0.0031 - val_loss: 0.0034 - val_mae: 0.0034\n",
      "Epoch 164/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0031 - mae: 0.0031 - val_loss: 0.0028 - val_mae: 0.0028\n",
      "Epoch 165/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0031 - mae: 0.0031 - val_loss: 0.0032 - val_mae: 0.0032\n",
      "Epoch 166/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0031 - mae: 0.0031 - val_loss: 0.0031 - val_mae: 0.0031\n",
      "Epoch 167/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0031 - mae: 0.0031 - val_loss: 0.0030 - val_mae: 0.0030\n",
      "Epoch 168/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0031 - mae: 0.0031 - val_loss: 0.0031 - val_mae: 0.0031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0031 - mae: 0.0031 - val_loss: 0.0032 - val_mae: 0.0032\n",
      "Epoch 170/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0031 - mae: 0.0031 - val_loss: 0.0032 - val_mae: 0.0032\n",
      "Epoch 171/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0031 - mae: 0.0031 - val_loss: 0.0030 - val_mae: 0.0030\n",
      "Epoch 172/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0031 - mae: 0.0031 - val_loss: 0.0031 - val_mae: 0.0031\n",
      "Epoch 173/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0031 - mae: 0.0031 - val_loss: 0.0031 - val_mae: 0.0031\n",
      "Epoch 174/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0031 - mae: 0.0031 - val_loss: 0.0031 - val_mae: 0.0031\n",
      "Epoch 175/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0031 - mae: 0.0031 - val_loss: 0.0030 - val_mae: 0.0030\n",
      "Epoch 176/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0031 - mae: 0.0031 - val_loss: 0.0031 - val_mae: 0.0031\n",
      "Epoch 177/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0030 - mae: 0.0030 - val_loss: 0.0031 - val_mae: 0.0031\n",
      "Epoch 178/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0030 - mae: 0.0030 - val_loss: 0.0030 - val_mae: 0.0030\n",
      "Epoch 179/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0030 - mae: 0.0030 - val_loss: 0.0031 - val_mae: 0.0031\n",
      "Epoch 180/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0030 - mae: 0.0030 - val_loss: 0.0031 - val_mae: 0.0031\n",
      "Epoch 181/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0030 - mae: 0.0030 - val_loss: 0.0030 - val_mae: 0.0030\n",
      "Epoch 182/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0030 - mae: 0.0030 - val_loss: 0.0031 - val_mae: 0.0031\n",
      "Epoch 183/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0030 - mae: 0.0030 - val_loss: 0.0029 - val_mae: 0.0029\n",
      "Epoch 184/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0030 - mae: 0.0030 - val_loss: 0.0030 - val_mae: 0.0030\n",
      "Epoch 185/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0030 - mae: 0.0030 - val_loss: 0.0031 - val_mae: 0.0031\n",
      "Epoch 186/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0030 - mae: 0.0030 - val_loss: 0.0031 - val_mae: 0.0031\n",
      "Epoch 187/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0030 - mae: 0.0030 - val_loss: 0.0030 - val_mae: 0.0030\n",
      "Epoch 188/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0030 - mae: 0.0030 - val_loss: 0.0028 - val_mae: 0.0028\n",
      "Epoch 189/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0030 - mae: 0.0030 - val_loss: 0.0032 - val_mae: 0.0032\n",
      "Epoch 190/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0030 - mae: 0.0030 - val_loss: 0.0031 - val_mae: 0.0031\n",
      "Epoch 191/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0030 - mae: 0.0030 - val_loss: 0.0029 - val_mae: 0.0029\n",
      "Epoch 192/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0030 - mae: 0.0030 - val_loss: 0.0031 - val_mae: 0.0031\n",
      "Epoch 193/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0030 - mae: 0.0030 - val_loss: 0.0028 - val_mae: 0.0028\n",
      "Epoch 194/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0030 - mae: 0.0030 - val_loss: 0.0029 - val_mae: 0.0029\n",
      "Epoch 195/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0030 - mae: 0.0030 - val_loss: 0.0030 - val_mae: 0.0030\n",
      "Epoch 196/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0030 - mae: 0.0030 - val_loss: 0.0029 - val_mae: 0.0029\n",
      "Epoch 197/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0029 - mae: 0.0029 - val_loss: 0.0028 - val_mae: 0.0028\n",
      "Epoch 198/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0029 - mae: 0.0029 - val_loss: 0.0028 - val_mae: 0.0028\n",
      "Epoch 199/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0029 - mae: 0.0029 - val_loss: 0.0028 - val_mae: 0.0028\n",
      "Epoch 200/200\n",
      "1600000/1600000 [==============================] - 25s 16us/sample - loss: 0.0029 - mae: 0.0029 - val_loss: 0.0029 - val_mae: 0.0029\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f33c4e23510>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model\n",
    "model.fit(X_input, X_delta, epochs=200,batch_size=128,validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = 'data/ANN_weights_global_'+datetime.datetime.now().strftime(\"%Y_%m_%d-%H_%M_%S\")\n",
    "os.makedirs(folder_name, exist_ok=True)\n",
    "    \n",
    "model.save_weights(folder_name+'/weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:lorenz96]",
   "language": "python",
   "name": "conda-env-lorenz96-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
